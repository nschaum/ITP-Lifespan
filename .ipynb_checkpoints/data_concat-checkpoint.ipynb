{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d37438a2-727c-45c3-88a6-7e09775c5be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    population cohort site sex id group Rx(ppm)  \\\n",
      "Lifespan_C2004.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2005.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2006.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2007.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2009.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2010.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2011.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2012.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2013.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2014.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2015.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2016.xlsx          X      X    X   X  X     X       X   \n",
      "Lifespan_C2017.xlsx          X      X    X   X  X     X       X   \n",
      "\n",
      "                    age_initiation(mo) status dead age(days) Status Dead Age  \\\n",
      "Lifespan_C2004.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2005.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2006.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2007.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2009.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2010.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2011.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2012.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2013.xlsx                  X      X    X         X                   \n",
      "Lifespan_C2014.xlsx                  X                            X    X   X   \n",
      "Lifespan_C2015.xlsx                  X      X    X                             \n",
      "Lifespan_C2016.xlsx                  X      X    X                             \n",
      "Lifespan_C2017.xlsx                  X      X    X                             \n",
      "\n",
      "                    DOB DOE age  \n",
      "Lifespan_C2004.xlsx              \n",
      "Lifespan_C2005.xlsx              \n",
      "Lifespan_C2006.xlsx              \n",
      "Lifespan_C2007.xlsx              \n",
      "Lifespan_C2009.xlsx              \n",
      "Lifespan_C2010.xlsx              \n",
      "Lifespan_C2011.xlsx              \n",
      "Lifespan_C2012.xlsx              \n",
      "Lifespan_C2013.xlsx              \n",
      "Lifespan_C2014.xlsx   X   X      \n",
      "Lifespan_C2015.xlsx           X  \n",
      "Lifespan_C2016.xlsx           X  \n",
      "Lifespan_C2017.xlsx           X  \n"
     ]
    }
   ],
   "source": [
    "# This notebook assumes you have downloaded the ITP lifespan data in .xlsx files from https://phenome.jax.org/projects/ITP1\n",
    "# It is a bit of a pain to download as there is one file for each year, accessible only through several clicks each\n",
    "# Most of these files have the same format (same column headers), but there are a few differences (C2014 in particular has extra columns)\n",
    "# C2014 and after also change the name of the 'age(days)' column to 'age'\n",
    "# Finally there are empty cells, especially in the age_initiation(mo) column in cases where the row is a control animal\n",
    "# We need to fill those empty cells or else they will cause an error when processing those files in future steps\n",
    "\n",
    "# packages needed for manipulating dataframes and uploading and concatenating xlsx files \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# suppress the warning about one of the Excel files having an unknonwn extension or (more likely in this case) an unknown feature in the file.\n",
    "# this typically won't affect anything, and this is partly why it is good to use csvs! But ITP provided .xlsx files...\n",
    "import warnings\n",
    "from openpyxl import Workbook\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "# First we need to input the raw data provided by the ITP and make sure the files are formatted in exactly the same way so that we can later \n",
    "# concatenate them into a single file. First, we will print the column headers contained in each file to make sure they match. If they don't\n",
    "# we'll need to make them match so that concatenation works correctly, and so that there are no extra columns with empty cells created, which \n",
    "# will cause problems later on (empty cells are bad!). \n",
    "\n",
    "data_folder = 'C:\\\\Users\\\\ndsch\\\\Data\\\\ITP-Lifespan-Data\\\\ITP_raw_data\\\\'\n",
    "file_names = [file for file in os.listdir(data_folder) if file.endswith('.xlsx')]\n",
    "\n",
    "unique_columns = {}\n",
    "column_files = {}\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    temp_df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "    # Count unique column occurrences and track the file names\n",
    "    for column in temp_df.columns:\n",
    "        if column in unique_columns:\n",
    "            unique_columns[column] += 1\n",
    "            column_files[column].append(file_name)\n",
    "        else:\n",
    "            unique_columns[column] = 1\n",
    "            column_files[column] = [file_name]\n",
    "\n",
    "# Create a DataFrame to represent the table\n",
    "table_df = pd.DataFrame(index=file_names, columns=unique_columns.keys())\n",
    "\n",
    "# Fill the table with the information about column header presence in each file\n",
    "for column, files in column_files.items():\n",
    "    for file in files:\n",
    "        table_df.at[file, column] = 'X'\n",
    "\n",
    "print(table_df.fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f411bbcd-7bd5-4384-a51d-cc5f15f94388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headers of the concatenated DataFrame:\n",
      "Index(['population', 'cohort', 'site', 'sex', 'id', 'group', 'Rx(ppm)',\n",
      "       'age_initiation(mo)', 'status', 'dead', 'age(days)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# From the above output, you can see that Lifespan_C2014 is formatted quite differently from the other files, and 2015, 2016, 2017 use 'age'\n",
    "# instead of 'age(days)'. Let's standardize the column headers and get rid of the extra DOB and DOE data from the 2014 file.\n",
    "dfs = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    temp_df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "    # Modify the DataFrame according to the specified conditions\n",
    "    if file_name == 'Lifespan_C2014.xlsx':\n",
    "        temp_df = temp_df.drop(columns=['DOB', 'DOE'])\n",
    "        temp_df = temp_df.rename(columns={'Status': 'status', 'Dead': 'dead', 'Age': 'age(days)'})\n",
    "    elif file_name in ['Lifespan_C2015.xlsx', 'Lifespan_C2016.xlsx','Lifespan_C2017.xlsx']:\n",
    "        temp_df = temp_df.rename(columns={'age': 'age(days)'})\n",
    "\n",
    "    dfs.append(temp_df)\n",
    "\n",
    "# Concatenate all the data into a single DataFrame\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#print the column headers to manually check everything looks good in the concatenated df\n",
    "print(\"Column headers of the concatenated DataFrame:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3b8f5a04-2ef3-4893-b783-3cd5f2842f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-numeric values found in the 'age(days)' column.\n"
     ]
    }
   ],
   "source": [
    "# code to check the age(days) column as I keep getting an error in the streamlit app script that this column contains non-numeric values.\n",
    "# Find rows with non-numeric values in the 'age(days)' column\n",
    "non_numeric_age_rows = df[pd.to_numeric(df['age(days)'], errors='coerce').isna()]\n",
    "\n",
    "# Print rows with non-numeric values in the 'age(days)' column\n",
    "if not non_numeric_age_rows.empty:\n",
    "    print(\"Rows with non-numeric values in the 'age(days)' column:\")\n",
    "    print(non_numeric_age_rows)\n",
    "else:\n",
    "    print(\"No non-numeric values found in the 'age(days)' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "21fa3a7b-0576-48f0-a117-64ce5fe35def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             group cohort         Rx(ppm) age_initiation(mo)\n",
      "             17aE2  C2009             4.8               10.0\n",
      "         17aE2_16m  C2016            14.4               16.0\n",
      "         17aE2_20m  C2016            14.4               20.0\n",
      "          17aE2_hi  C2011              14               10.0\n",
      "          4-OH-PBN  C2004             315                4.0\n",
      "               ACA  C2012            1000               16.0\n",
      "               ACA  C2009          1000.0                4.0\n",
      "            ACA_hi  C2013            2500                4.0\n",
      "            ACA_lo  C2013             400                4.0\n",
      "           ACA_mid  C2013            1000                4.0\n",
      "               Asp  C2004              21                4.0\n",
      "           Asp_200  C2014             200               11.0\n",
      "            Asp_60  C2014              60               11.0\n",
      "                BD  C2017          100000                6.0\n",
      "           CAPE_hi  C2005             300                4.0\n",
      "           CAPE_lo  C2005              30                4.0\n",
      "              CAPT  C2017             180                5.0\n",
      "                CC  C2016            30.0                8.0\n",
      "              Cana  C2016           180.0                7.0\n",
      "              Capt  C2017             180                5.0\n",
      "           Control  C2011               0                NaN\n",
      "           Control  C2010               0                NaN\n",
      "           Control  C2013               0                NaN\n",
      "           Control  C2014               0                NaN\n",
      "           Control  C2017               0                NaN\n",
      "           Control  C2015               0                NaN\n",
      "           Control  C2009             0.0                NaN\n",
      "           Control  C2004               0                NaN\n",
      "           Control  C2005               0                NaN\n",
      "           Control  C2006               0                NaN\n",
      "           Control  C2016             0.0                NaN\n",
      "           Control  C2007               0                NaN\n",
      "           Control  C2012               0                NaN\n",
      "               Cur  C2007            2000                4.0\n",
      "              DMAG  C2015              30                  6\n",
      "              Enal  C2005             120                4.0\n",
      "             FO_hi  C2010           50000                9.0\n",
      "             FO_lo  C2010           15000                9.0\n",
      "               GGA  C2016           600.0                9.0\n",
      "               GTE  C2007            2000                4.0\n",
      "               Gly  C2014           80000                9.0\n",
      "               HBX  C2012               1               15.0\n",
      "           INT-767  C2012             180               10.0\n",
      "               Inu  C2014             600               11.0\n",
      "               Leu  C2017           40000                5.0\n",
      "                MB  C2009            28.0                4.0\n",
      "              MCTO  C2007           60000                4.0\n",
      "            MIF098  C2016           240.0                8.0\n",
      "               Met  C2011            1000                9.0\n",
      "           MetRapa  C2011        1000, 14                9.0\n",
      "               Min  C2015             300                  6\n",
      "             MitoQ  C2015             100                  7\n",
      "              NDGA  C2004            2500                9.0\n",
      "           NDGA_hi  C2010            5000                6.0\n",
      "           NDGA_lo  C2010             800                6.0\n",
      "          NDGA_mid  C2010            2500                6.0\n",
      "               NFP  C2004             200                4.0\n",
      "                NR  C2016          1000.0                8.0\n",
      "               OAA  C2007            2200                4.0\n",
      "             PB125  C2017 see publication                5.0\n",
      "              Prot  C2011             600               10.0\n",
      "            RaAc16  C2017      14.7, 1000               16.0\n",
      "             RaAc9  C2017      14.7, 1000                9.0\n",
      "              Rapa  C2006              14                9.0\n",
      "              Rapa  C2005              14               20.0\n",
      "           Rapa_hi  C2009            42.0                9.0\n",
      "Rapa_hi_continuous  C2015              42                 20\n",
      "     Rapa_hi_cycle  C2015              42                 20\n",
      "Rapa_hi_start_stop  C2015              42         20 thru 23\n",
      "           Rapa_lo  C2009             4.7                9.0\n",
      "          Rapa_mid  C2009            14.0                9.0\n",
      "               Res  C2007             300                4.0\n",
      "            Res_hi  C2006            1200               12.0\n",
      "            Res_lo  C2006             300               12.0\n",
      "            Sim_hi  C2006             120               10.0\n",
      "            Sim_lo  C2006              12               10.0\n",
      "               Sul  C2017               5                5.0\n",
      "               Syr  C2017             300                5.0\n",
      "            TM5441  C2014              60               11.0\n",
      "                UA  C2013            2000               10.0\n",
      "              UDCA  C2011            5000                5.0\n",
      "              bGPA  C2015            3300                  6\n"
     ]
    }
   ],
   "source": [
    "# Everything looks good. Now let's check what we are working with in terms of different treatments. \n",
    "# Let's output a list of all the unique treatment names in the 'group' column, and corresponding values of interest\n",
    "# I know already that the same treatment was e.g. performed on different cohorts, or at different doses, or at different ages of initiation\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "unique_combinations = df[['group', 'cohort', 'Rx(ppm)', 'age_initiation(mo)']].drop_duplicates().sort_values('group')\n",
    "print(unique_combinations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f05b733b-5bf7-49f4-84ac-eb171a7485b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 has two values of capt and CAPT. Looking at the xlsx it seems one row was misnamed with all capitals, so let's change that to lowercase\n",
    "df['group'] = df['group'].replace('CAPT', 'Capt')\n",
    "\n",
    "# The group names sometimes have '_hi' or '_low' or other things. Let's add a column called treatment that just contains the drug name\n",
    "# but retains the group column in case we want to use it later. This will make grouping by e.g. \"rapa\" easier down the road.\n",
    "def extract_treatment(group):\n",
    "    if '_' in group:\n",
    "        return group.split('_')[0]\n",
    "    else:\n",
    "        return group\n",
    "df['treatment'] = df['group'].apply(extract_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f6c65c6-0940-40de-9992-160bfc7f55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's deal with a few special cases like combination treatments, treatments that were stopped rather than continuous,\n",
    "# and instances of custom entries like \"20 thru 23\" in the age_initiation(mo) column.\n",
    "\n",
    "# Add new columns with default value None\n",
    "df['treatment2'] = None\n",
    "df['Rx(ppm)2'] = None\n",
    "df['age_cessation(mo)'] = None\n",
    "df['notes'] = None\n",
    "\n",
    "# Update the specified rows based on the 'group' values\n",
    "df.loc[df['group'] == 'MetRapa', ['treatment', 'treatment2', 'Rx(ppm)', 'Rx(ppm)2', 'notes']] = ['Met', 'Rapa', 1000, 14, 'combo']\n",
    "df.loc[df['group'] == 'RaAc16', ['treatment', 'treatment2', 'Rx(ppm)', 'Rx(ppm)2', 'notes']] = ['Rapa', 'ACA', 14.7, 1000, 'combo']\n",
    "df.loc[df['group'] == 'RaAc9', ['treatment', 'treatment2', 'Rx(ppm)', 'Rx(ppm)2', 'notes']] = ['Rapa', 'ACA', 14.7, 1000, 'combo']\n",
    "df.loc[df['group'] == 'Rapa_hi_cycle', ['notes']] = ['Rapa on every other month']\n",
    "df.loc[df['group'] == 'Rapa_hi_start_stop', ['age_initiation(mo)', 'age_cessation(mo)', 'notes']] = [20, 23, 'Rapa from 20 mo to 23 mo only']\n",
    "df.loc[df['group'] == 'PB125', ['Rx(ppm)', 'notes']] = [0, 'combo supplement of Carnisol (3.2 ppm), Luteolin (4.8 ppm), Withaferin A (1 ppm)'] \n",
    "#df.loc[df['group'] == 'PB125', ['Rx(ppm)', 'notes']] = [np.nan, 'combo supplement of Carnisol (3.2 ppm), Luteolin (4.8 ppm), Withaferin A (1 ppm)'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7610fb58-3fe5-4e41-86c4-80a885e6f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatment              group cohort  Rx(ppm)  age_initiation(mo)\n",
      "    17aE2              17aE2  C2009      4.8                  10\n",
      "    17aE2          17aE2_16m  C2016     14.4                  16\n",
      "    17aE2          17aE2_20m  C2016     14.4                  20\n",
      "    17aE2           17aE2_hi  C2011     14.0                  10\n",
      " 4-OH-PBN           4-OH-PBN  C2004    315.0                   4\n",
      "      ACA                ACA  C2012   1000.0                  16\n",
      "      ACA                ACA  C2009   1000.0                   4\n",
      "      ACA             ACA_hi  C2013   2500.0                   4\n",
      "      ACA             ACA_lo  C2013    400.0                   4\n",
      "      ACA            ACA_mid  C2013   1000.0                   4\n",
      "      Asp                Asp  C2004     21.0                   4\n",
      "      Asp            Asp_200  C2014    200.0                  11\n",
      "      Asp             Asp_60  C2014     60.0                  11\n",
      "       BD                 BD  C2017 100000.0                   6\n",
      "     CAPE            CAPE_hi  C2005    300.0                   4\n",
      "     CAPE            CAPE_lo  C2005     30.0                   4\n",
      "       CC                 CC  C2016     30.0                   8\n",
      "     Cana               Cana  C2016    180.0                   7\n",
      "     Capt               Capt  C2017    180.0                   5\n",
      "  Control            Control  C2013      0.0                   0\n",
      "  Control            Control  C2011      0.0                   0\n",
      "  Control            Control  C2010      0.0                   0\n",
      "  Control            Control  C2014      0.0                   0\n",
      "  Control            Control  C2017      0.0                   0\n",
      "  Control            Control  C2012      0.0                   0\n",
      "  Control            Control  C2015      0.0                   0\n",
      "  Control            Control  C2004      0.0                   0\n",
      "  Control            Control  C2005      0.0                   0\n",
      "  Control            Control  C2006      0.0                   0\n",
      "  Control            Control  C2009      0.0                   0\n",
      "  Control            Control  C2007      0.0                   0\n",
      "  Control            Control  C2016      0.0                   0\n",
      "      Cur                Cur  C2007   2000.0                   4\n",
      "     DMAG               DMAG  C2015     30.0                   6\n",
      "     Enal               Enal  C2005    120.0                   4\n",
      "       FO              FO_hi  C2010  50000.0                   9\n",
      "       FO              FO_lo  C2010  15000.0                   9\n",
      "      GGA                GGA  C2016    600.0                   9\n",
      "      GTE                GTE  C2007   2000.0                   4\n",
      "      Gly                Gly  C2014  80000.0                   9\n",
      "      HBX                HBX  C2012      1.0                  15\n",
      "  INT-767            INT-767  C2012    180.0                  10\n",
      "      Inu                Inu  C2014    600.0                  11\n",
      "      Leu                Leu  C2017  40000.0                   5\n",
      "       MB                 MB  C2009     28.0                   4\n",
      "     MCTO               MCTO  C2007  60000.0                   4\n",
      "   MIF098             MIF098  C2016    240.0                   8\n",
      "      Met                Met  C2011   1000.0                   9\n",
      "      Met            MetRapa  C2011   1000.0                   9\n",
      "      Min                Min  C2015    300.0                   6\n",
      "    MitoQ              MitoQ  C2015    100.0                   7\n",
      "     NDGA               NDGA  C2004   2500.0                   9\n",
      "     NDGA            NDGA_hi  C2010   5000.0                   6\n",
      "     NDGA            NDGA_lo  C2010    800.0                   6\n",
      "     NDGA           NDGA_mid  C2010   2500.0                   6\n",
      "      NFP                NFP  C2004    200.0                   4\n",
      "       NR                 NR  C2016   1000.0                   8\n",
      "      OAA                OAA  C2007   2200.0                   4\n",
      "    PB125              PB125  C2017      NaN                   5\n",
      "     Prot               Prot  C2011    600.0                  10\n",
      "     Rapa             RaAc16  C2017     14.7                  16\n",
      "     Rapa              RaAc9  C2017     14.7                   9\n",
      "     Rapa               Rapa  C2006     14.0                   9\n",
      "     Rapa               Rapa  C2005     14.0                  20\n",
      "     Rapa            Rapa_hi  C2009     42.0                   9\n",
      "     Rapa Rapa_hi_continuous  C2015     42.0                  20\n",
      "     Rapa      Rapa_hi_cycle  C2015     42.0                  20\n",
      "     Rapa Rapa_hi_start_stop  C2015     42.0                  20\n",
      "     Rapa            Rapa_lo  C2009      4.7                   9\n",
      "     Rapa           Rapa_mid  C2009     14.0                   9\n",
      "      Res                Res  C2007    300.0                   4\n",
      "      Res             Res_hi  C2006   1200.0                  12\n",
      "      Res             Res_lo  C2006    300.0                  12\n",
      "      Sim             Sim_hi  C2006    120.0                  10\n",
      "      Sim             Sim_lo  C2006     12.0                  10\n",
      "      Sul                Sul  C2017      5.0                   5\n",
      "      Syr                Syr  C2017    300.0                   5\n",
      "   TM5441             TM5441  C2014     60.0                  11\n",
      "       UA                 UA  C2013   2000.0                  10\n",
      "     UDCA               UDCA  C2011   5000.0                   5\n",
      "     bGPA               bGPA  C2015   3300.0                   6\n"
     ]
    }
   ],
   "source": [
    "# Now let's fill missing cells in age_initiation and remove the decimal from the age_initiation column and standardize the Rx(ppm) column\n",
    "df['age_initiation(mo)'] = df['age_initiation(mo)'].fillna(0)\n",
    "# Remove the decimal place from 'age_initiation(mo)'\n",
    "df['age_initiation(mo)'] = df['age_initiation(mo)'].astype(int)\n",
    "# Add a decimal to all values in Rx(ppm) for consistency\n",
    "df['Rx(ppm)'] = df['Rx(ppm)'].astype(float).round(1)\n",
    "# Convert age(days) to integers\n",
    "df['age(days)'] = df['age(days)'].astype(int)\n",
    "# Convert 'dead' to boolean\n",
    "df['dead'] = df['dead'].astype(bool)\n",
    "\n",
    "# Quick manual check to make sure it all looks good:\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "unique_combinations = df[['treatment','group', 'cohort', 'Rx(ppm)', 'age_initiation(mo)']].drop_duplicates().sort_values('group')\n",
    "print(unique_combinations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7e6065cf-7af5-4646-b3f8-fe32c7a49455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp code to output a CSV with the unique values of treatment so that can manually enter the full drug names in a corresponding column\n",
    "# Uncomment the following lines to run if desired\n",
    "\n",
    "#unique_treatments = df[['treatment']].drop_duplicates().sort_values('treatment')\n",
    "#output_folder = 'C:\\\\Users\\\\ndsch\\\\Data\\\\ITP-Lifespan-Data\\\\ITP_meta_data\\\\'\n",
    "#output_file_name = 'ITP_2004-2017_treatmentss.csv'\n",
    "#output_file_path = os.path.join(output_folder, output_file_name)\n",
    "#unique_treatments.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c618e352-5d6b-45a5-b8c6-16c52b137365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After manually adding full drug names (had trouble extracting them from the website directly), save as a new csv, import, and combine it with df\n",
    "# Added a few extra steps now that we have treatments with two drugs\n",
    "\n",
    "data_path = 'C:\\\\Users\\\\ndsch\\\\Data\\\\ITP-Lifespan-Data\\\\ITP_meta_data\\\\ITP_2004-2017_treatments_full.csv'\n",
    "drug_names = pd.read_csv(data_path)\n",
    "#df = pd.merge(df, drug_names, on=\"treatment\")\n",
    "\n",
    "\n",
    "# First merge using 'treatment' column\n",
    "df = pd.merge(df, drug_names, on=\"treatment\", how='left')\n",
    "\n",
    "# Second merge using 'treatment2' column and a temporary DataFrame\n",
    "temp_df = pd.merge(df, drug_names, left_on=\"treatment2\", right_on=\"treatment\", how='left')\n",
    "\n",
    "# Rename the 'full_name_y' column in the temporary DataFrame to 'full_name2'\n",
    "temp_df = temp_df.rename(columns={'full_name_y': 'full_name2'})\n",
    "\n",
    "# Combine the 'full_name2' column from the temporary DataFrame with the main DataFrame\n",
    "df['full_name2'] = temp_df['full_name2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4b3de4f7-8301-469f-8504-30bbda7a9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we finally have a concatenated and minimally processed data file.\n",
    "# Let's output a new file called ITP_2004-2016_concat.csv.\n",
    "# We'll use that as the starting file in other notebooks to do make things like Kaplan Meier curves.\n",
    "# I want to save this file because there are a few special cases, like group = Rapa_hi_start_stop that are going to be harder to deal with and I'd like to just get something\n",
    "# up and running before dealing with that. So we'll have two notebooks most likely - one that removes those special cases, and another that includes them.\n",
    "\n",
    "output_folder = 'C:\\\\Users\\\\ndsch\\\\Data\\\\ITP-Lifespan-Data\\\\ITP_processed_data\\\\'\n",
    "output_file_name = 'ITP_2004-2017_concat.csv'\n",
    "output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
